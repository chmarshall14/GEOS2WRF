# GEOS2WRF

You will have to change the directory paths in these scripts to use them. It also assumes you have GEOS2WRF and WRF-4.0 compiled on your system. 

These are python scripts that take a start date and end date and time as inputs, then download the necessary data files from NASA and process them using GEOS2WPS and the utilities createLANDSEA, createRH, and createSOILHGT. They can be found at this github. 
The scripts are broadly organized into three sections: a series of download scripts, a series of scripts that run geos2wps and the utilities, and a script that concatenates all the required fields to prepare files that are ready to be used by Metgrid. We are currently working on a wrapper script that will run all of these individuals scripts for us. 
The download scripts: There is a single download script called ‘download_wrapper” that should download every file you need given an start and end time. It also organizes the files into a storm_startdate with subfolders for each field. 
If that doesn’t work, there are scripts that download each individual file type. These are called <file_name>.py, for instance DELP.py or MET1.py. We originally had a single download script, but it was too unwieldy and kept being killed. When I tried to use these, I generally found that the connection between NYU prince and the NASA GEOS Data host was being interrupted, which caused the jobs to be killed. A current workaround is to use the scripts to print the url names into a wget file and then use a wget command, which can be modified to keep trying if the connection is interrupted rather than to just stop altogether. As part of the wraparound script I am working on making this as smooth as possible. Up to now I was just copy and pasting the list of URLs into a wget file, which worked but there is likely a better way to do it. 
The processing scripts: The scripts named GEOS_<filename> run geos2wps on each file you have downloaded, and the scripts named create<utility> run createRH, createLANDSEA and createSOILHGT.  
These scripts are broken up by GEOS file to be processed, there is one for each downloaded file. They link in the executable geos2wps, create a namelist and run geos2wps for each time step. 
Once you have processed all of the fields in geos2wps, you can run the utility scripts that concatenate the files you need into a geos:timestamp file and run the utility executable.
The concatenation script: once everything is done, you can move all of the files you have processed into the same folder (the wraparound script I am writing will do this for you), and catGEOS.py will get everything you need into the files GEOS:TIMESTAMP to be ready to be used by metgrid. 
